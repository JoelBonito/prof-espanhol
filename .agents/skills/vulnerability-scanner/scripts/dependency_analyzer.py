#!/usr/bin/env python3
"""
Skill: vulnerability-scanner
Script: dependency_analyzer.py
Purpose: Standalone dependency security audit (supply chain analysis)
Usage: python dependency_analyzer.py <project_path> [--output json|summary]
Output: JSON with dependency findings

This script validates:
1. Lock file presence and integrity
2. Known vulnerabilities via npm audit / pip-audit
3. Outdated dependencies detection
4. Dependency age and maintenance status
"""
import subprocess
import json
import os
import sys
import argparse
from pathlib import Path
from typing import Dict, List, Any
from datetime import datetime

# Fix Windows console encoding
try:
    sys.stdout.reconfigure(encoding='utf-8', errors='replace')
    sys.stderr.reconfigure(encoding='utf-8', errors='replace')
except AttributeError:
    pass


# ============================================================================
#  CONFIGURATION
# ============================================================================

LOCK_FILES = {
    "npm": {"pkg": "package.json", "locks": ["package-lock.json", "npm-shrinkwrap.json"]},
    "yarn": {"pkg": "package.json", "locks": ["yarn.lock"]},
    "pnpm": {"pkg": "package.json", "locks": ["pnpm-lock.yaml"]},
    "pip": {"pkg": "requirements.txt", "locks": ["requirements.txt"]},
    "pipenv": {"pkg": "Pipfile", "locks": ["Pipfile.lock"]},
    "poetry": {"pkg": "pyproject.toml", "locks": ["poetry.lock"]},
}

SKIP_DIRS = {'node_modules', '.git', 'dist', 'build', '__pycache__', '.venv', 'venv', '.next'}


# ============================================================================
#  SCANNING FUNCTIONS
# ============================================================================

def check_lock_files(project_path: str) -> Dict[str, Any]:
    """Check for lock file presence and integrity."""
    results = {"findings": [], "managers_detected": [], "locks_found": []}

    for manager, config in LOCK_FILES.items():
        pkg_path = Path(project_path) / config["pkg"]
        if not pkg_path.exists():
            continue

        results["managers_detected"].append(manager)
        has_lock = False
        for lock_file in config["locks"]:
            lock_path = Path(project_path) / lock_file
            if lock_path.exists():
                has_lock = True
                results["locks_found"].append(lock_file)

        if not has_lock:
            results["findings"].append({
                "type": "missing_lock_file",
                "severity": "high",
                "manager": manager,
                "message": f"{manager}: No lock file found. Supply chain integrity at risk.",
                "recommendation": f"Run the package manager install to generate a lock file."
            })

    return results


def run_npm_audit(project_path: str) -> Dict[str, Any]:
    """Run npm audit for vulnerability detection."""
    results = {"findings": [], "severity_counts": {}}

    if not (Path(project_path) / "package.json").exists():
        return results

    try:
        result = subprocess.run(
            ["npm", "audit", "--json"],
            cwd=project_path,
            capture_output=True,
            text=True,
            timeout=60
        )

        try:
            audit_data = json.loads(result.stdout)
            vulnerabilities = audit_data.get("vulnerabilities", {})

            severity_count = {"critical": 0, "high": 0, "moderate": 0, "low": 0}
            for name, vuln in vulnerabilities.items():
                sev = vuln.get("severity", "low").lower()
                if sev in severity_count:
                    severity_count[sev] += 1

            results["severity_counts"] = severity_count
            total = sum(severity_count.values())

            if total > 0:
                results["findings"].append({
                    "type": "npm_audit",
                    "severity": "critical" if severity_count["critical"] > 0 else
                               "high" if severity_count["high"] > 0 else "moderate",
                    "message": f"npm audit: {severity_count['critical']} critical, "
                               f"{severity_count['high']} high, "
                               f"{severity_count['moderate']} moderate, "
                               f"{severity_count['low']} low",
                    "total_vulnerabilities": total
                })
        except json.JSONDecodeError:
            pass

    except FileNotFoundError:
        results["findings"].append({
            "type": "tool_missing",
            "severity": "low",
            "message": "npm not found in PATH. Skipping npm audit."
        })
    except subprocess.TimeoutExpired:
        results["findings"].append({
            "type": "timeout",
            "severity": "low",
            "message": "npm audit timed out after 60s."
        })

    return results


def check_outdated_npm(project_path: str) -> Dict[str, Any]:
    """Check for outdated npm dependencies."""
    results = {"findings": [], "outdated_count": 0}

    if not (Path(project_path) / "package.json").exists():
        return results

    try:
        result = subprocess.run(
            ["npm", "outdated", "--json"],
            cwd=project_path,
            capture_output=True,
            text=True,
            timeout=60
        )

        try:
            outdated = json.loads(result.stdout) if result.stdout.strip() else {}
            results["outdated_count"] = len(outdated)

            major_updates = []
            for pkg, info in outdated.items():
                current = info.get("current", "?")
                latest = info.get("latest", "?")
                if current != "?" and latest != "?":
                    curr_major = current.split(".")[0] if "." in current else current
                    lat_major = latest.split(".")[0] if "." in latest else latest
                    if curr_major != lat_major:
                        major_updates.append(f"{pkg}: {current} -> {latest}")

            if major_updates:
                results["findings"].append({
                    "type": "major_outdated",
                    "severity": "medium",
                    "message": f"{len(major_updates)} packages with major version updates available",
                    "packages": major_updates[:10]
                })

            if results["outdated_count"] > 20:
                results["findings"].append({
                    "type": "many_outdated",
                    "severity": "medium",
                    "message": f"{results['outdated_count']} outdated packages. Consider updating."
                })

        except json.JSONDecodeError:
            pass

    except (FileNotFoundError, subprocess.TimeoutExpired):
        pass

    return results


def check_outdated_pip(project_path: str) -> Dict[str, Any]:
    """Check for outdated pip dependencies."""
    results = {"findings": [], "outdated_count": 0}

    req_files = ["requirements.txt", "Pipfile", "pyproject.toml"]
    has_python = any((Path(project_path) / f).exists() for f in req_files)

    if not has_python:
        return results

    try:
        result = subprocess.run(
            [sys.executable, "-m", "pip", "list", "--outdated", "--format=json"],
            capture_output=True,
            text=True,
            timeout=60
        )

        try:
            outdated = json.loads(result.stdout) if result.stdout.strip() else []
            results["outdated_count"] = len(outdated)

            if len(outdated) > 10:
                results["findings"].append({
                    "type": "pip_outdated",
                    "severity": "low",
                    "message": f"{len(outdated)} outdated Python packages.",
                    "packages": [f"{p['name']}: {p.get('version','?')} -> {p.get('latest_version','?')}"
                                 for p in outdated[:10]]
                })

        except json.JSONDecodeError:
            pass

    except (FileNotFoundError, subprocess.TimeoutExpired):
        pass

    return results


# ============================================================================
#  MAIN
# ============================================================================

def run_full_analysis(project_path: str) -> Dict[str, Any]:
    """Execute full dependency analysis."""

    report = {
        "tool": "dependency_analyzer",
        "project": os.path.abspath(project_path),
        "timestamp": datetime.now().isoformat(),
        "scans": {},
        "summary": {
            "total_findings": 0,
            "by_severity": {"critical": 0, "high": 0, "medium": 0, "low": 0},
            "overall_status": "[OK] Dependencies secure"
        }
    }

    # 1. Lock files
    lock_result = check_lock_files(project_path)
    report["scans"]["lock_files"] = lock_result

    # 2. npm audit
    audit_result = run_npm_audit(project_path)
    report["scans"]["npm_audit"] = audit_result

    # 3. Outdated (npm)
    outdated_npm = check_outdated_npm(project_path)
    report["scans"]["outdated_npm"] = outdated_npm

    # 4. Outdated (pip)
    outdated_pip = check_outdated_pip(project_path)
    report["scans"]["outdated_pip"] = outdated_pip

    # Aggregate findings
    all_findings = []
    for scan in report["scans"].values():
        all_findings.extend(scan.get("findings", []))

    report["summary"]["total_findings"] = len(all_findings)
    for finding in all_findings:
        sev = finding.get("severity", "low")
        if sev in report["summary"]["by_severity"]:
            report["summary"]["by_severity"][sev] += 1

    # Determine status
    sev = report["summary"]["by_severity"]
    if sev["critical"] > 0:
        report["summary"]["overall_status"] = "[!!] CRITICAL: Vulnerable dependencies"
    elif sev["high"] > 0:
        report["summary"]["overall_status"] = "[!] HIGH: Dependency issues found"
    elif sev["medium"] > 0:
        report["summary"]["overall_status"] = "[?] REVIEW: Some dependencies need attention"

    return report


def main():
    parser = argparse.ArgumentParser(
        description="Dependency security analysis (supply chain audit)"
    )
    parser.add_argument("project_path", nargs="?", default=".",
                        help="Project directory to analyze")
    parser.add_argument("--output", choices=["json", "summary"], default="json",
                        help="Output format")

    args = parser.parse_args()

    if not os.path.isdir(args.project_path):
        print(json.dumps({"error": f"Directory not found: {args.project_path}"}))
        sys.exit(1)

    result = run_full_analysis(args.project_path)

    if args.output == "summary":
        print(f"\n{'=' * 60}")
        print(f"Dependency Analysis: {result['project']}")
        print(f"{'=' * 60}")
        print(f"Status: {result['summary']['overall_status']}")
        print(f"Total Findings: {result['summary']['total_findings']}")
        sev = result['summary']['by_severity']
        print(f"  Critical: {sev['critical']}")
        print(f"  High: {sev['high']}")
        print(f"  Medium: {sev['medium']}")
        print(f"  Low: {sev['low']}")

        lock_data = result['scans'].get('lock_files', {})
        if lock_data.get('managers_detected'):
            print(f"\nPackage Managers: {', '.join(lock_data['managers_detected'])}")
            print(f"Lock Files: {', '.join(lock_data.get('locks_found', ['none']))}")

        audit_data = result['scans'].get('npm_audit', {})
        if audit_data.get('severity_counts'):
            sc = audit_data['severity_counts']
            print(f"\nnpm audit: {sc.get('critical', 0)} critical, "
                  f"{sc.get('high', 0)} high, {sc.get('moderate', 0)} moderate")

        print(f"{'=' * 60}\n")
    else:
        print(json.dumps(result, indent=2))


if __name__ == "__main__":
    main()
